---
title: "Chapter 6"
author: "John Peach"
date: "4/1/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      cache = TRUE)
library(dplyr)
library(tidytext)
```

```{r}
library(topicmodels)
data("AssociatedPress")
AssociatedPress
```

```{r}
ap_lda <- LDA(AssociatedPress, k = 2, control = list(seed = 1234))
ap_lda
```
```{r}
library(tidytext)
ap_topics <- tidy(ap_lda, matrix = "beta")
ap_topics
```
```{r}
library(ggplot2)
library(dplyr)

ap_top_terms <- ap_topics %>% 
  group_by(topic) %>% 
  top_n(10, beta) %>% 
  ungroup() %>% 
  arrange(topic, -beta)

ap_top_terms %>% 
  mutate(term = reorder(term, beta)) %>% 
  ggplot(aes(term, beta, fill = factor(topic))) +
    geom_col(show.legend = FALSE) +
    facet_wrap(~ topic, scales = "free") +
    coord_flip()
```

```{r}
library(tidyr)

beta_spread <- ap_topics %>% 
  mutate(topic = paste0("topic", topic)) %>% 
  spread(topic, beta) %>% 
  dplyr::filter(topic1 > 0.001 | topic2 > 0.001) %>% 
  mutate(log_ratio = log2(topic2 / topic1))

beta_spread
```
```{r}
ap_documents <- tidy(ap_lda, matrix = "gamma")
ap_documents
```
```{r}
tidy(AssociatedPress) %>% 
  dplyr::filter(document == 6) %>% 
  arrange(desc(count))
```

```{r}
titles <- c("Twenty Thousand Leagues under the Sea", 
            "The War of the Worlds",
            "Pride and Prejudice",
            "Great Expectations")
library(gutenbergr)
books <- gutenberg_works(title %in% titles) %>% 
  gutenberg_download(meta_fields = "title")

```

```{r}
library(stringr)
reg <- regex("^chapter", ignore_case = TRUE)
by_chapter <- books %>% 
  group_by(title) %>% 
  mutate(chapter = cumsum(str_detect(text, reg))) %>% 
  ungroup() %>% 
  dplyr::filter(chapter > 0) %>% 
  unite(document, title, chapter)

by_chapter_word <- by_chapter %>% 
  unnest_tokens(word, text)

word_counts <- by_chapter_word %>% 
  anti_join(stop_words) %>% 
  count(document, word, sort = TRUE) %>% 
  ungroup()

word_counts
```
```{r}
chapters_dtm <- word_counts %>% 
  cast_dtm(document, word, n)

chapters_dtm
```

```{r}
chapters_lda <- LDA(chapters_dtm, k = 4, control = list(seed = 1234))
chapters_lda
```

```{r}
chapter_topics <- tidy(chapters_lda, matrix = "beta")
chapter_topics
```
```{r}
top_terms <- chapter_topics %>% 
  group_by(topic) %>% 
  top_n(5, beta) %>% 
  ungroup() %>% 
  arrange(topic, -beta)
top_terms
```
```{r}
library(ggplot2)

top_terms %>% 
  mutate(term = reorder(term, beta)) %>% 
  ggplot(aes(term, beta, fill = factor(topic))) +
    geom_col(show.legend = FALSE) +
    facet_wrap(~ topic, scales = "free") +
    coord_flip()
```

```{r}
chapters_gamma <- tidy(chapters_lda, matrix = "gamma")
chapters_gamma
```
```{r}
chapters_gamma <- chapters_gamma %>% 
  separate(document, c("title", "chapter"), sep = "_", convert = TRUE)
chapters_gamma
```
```{r}
chapters_gamma %>% 
  mutate(title = reorder(title, gamma * topic)) %>% 
  ggplot(aes(factor(topic), gamma)) +
    geom_boxplot() +
    facet_wrap(~ title)
```

```{r}
chapter_classifications <- chapters_gamma %>% 
  group_by(title, chapter) %>% 
  top_n(1, gamma) %>% 
  ungroup()

chapter_classifications
```
```{r}
book_topics <- chapter_classifications %>% 
  count(title, topic) %>% 
  group_by(title) %>% 
  top_n(1, n) %>% 
  ungroup() %>% 
  transmute(consensus = title, topic)

chapter_classifications %>% 
  inner_join(book_topics, by = "topic") %>% 
  dplyr::filter(title != consensus)
```
```{r}
assignments <- augment(chapters_lda, data = chapters_dtm)
assignments
```
```{r}
assignments <- assignments %>% 
  separate(document, c("title", "chapter"), sep = "_", convert = TRUE) %>% 
  inner_join(book_topics, by = c(".topic" = "topic"))
assignments
```
```{r}
library(scales)
assignments %>% 
  count(title, consensus, wt = count) %>% 
  group_by(title) %>% 
  mutate(percentage = n / sum(n)) %>% 
  ggplot(aes(consensus, title, fill = percentage)) +
    geom_tile() +
    scale_fill_gradient2(high = 'red', label = percent_format()) +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 90, hjust = 1),
          panel.grid = element_blank()) +
    labs(x = "Book words were assignment to",
         y = "Book words came from",
         fill = "% assignments")
```
```{r}
wrong_words <- assignments %>% 
  dplyr::filter(title != consensus)
wrong_words
```

```{r}
wrong_words %>% 
  count(title, consensus, term, wt = count) %>% 
  ungroup() %>% 
  arrange(desc(n))
```
```{r}
word_counts %>% 
  dplyr::filter(word == "flopson")
```

```{r}
library(mallet)

collapsed <- by_chapter_word %>% 
  anti_join(stop_words, by = "word") %>% 
  mutate(word = str_replace(word, "'", "")) %>% 
  group_by(document) %>% 
  summarise(text = paste(word, collapse = " "))

file.create(empty_file <- tempfile())
docs <- mallet.import(collapsed$document, collapsed$text, empty_file)

mallet_model <- MalletLDA(num.topics = 4)
mallet_model$loadDocuments(docs)
mallet_model$train(100)
```

```{r}
tidy(mallet_model)
tidy(mallet_model, matrix = "gamma")
term_counts <- rename(word_counts, term = word)
augment(mallet_model, term_counts)
```

